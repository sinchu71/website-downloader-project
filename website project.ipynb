{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMSk4k8qzLuYGvMxdw7i1Gt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sinchu71/website-downloader-project/blob/main/website%20project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFBdkJzErM64",
        "outputId": "24c60e3a-65de-4bd2-bac4-7f5f1ba2ed09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.12.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2024.12.14)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.6)\n"
          ]
        }
      ],
      "source": [
        "pip install requests beautifulsoup4\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0GM1GugtrbAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urlparse, urljoin\n",
        "\n",
        "# Function to download the page content\n",
        "def download_page(url, depth, base_dir, visited_urls, crawl_depth_limit):\n",
        "    if depth > crawl_depth_limit or url in visited_urls:\n",
        "        return\n",
        "\n",
        "    # Mark this URL as visited\n",
        "    visited_urls.add(url)\n",
        "\n",
        "    # Fetch the page content\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        page_content = response.text\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"Error downloading {url}: {e}\")\n",
        "        return\n",
        "\n",
        "    # Save HTML content to the local directory\n",
        "    save_html(url, page_content, base_dir)\n",
        "\n",
        "    # Parse the HTML to extract links, images, and scripts\n",
        "    soup = BeautifulSoup(page_content, 'html.parser')\n",
        "\n",
        "    # Crawl links and download additional resources\n",
        "    download_resources(url, soup, base_dir, depth, visited_urls, crawl_depth_limit)\n",
        "\n",
        "    # Find all internal links on the page and visit them recursively\n",
        "    for link_tag in soup.find_all(\"a\", href=True):\n",
        "        link = link_tag['href']\n",
        "        link_url = urljoin(url, link)\n",
        "        download_page(link_url, depth + 1, base_dir, visited_urls, crawl_depth_limit)\n",
        "\n",
        "# Function to download resources (images, js)\n",
        "def download_resources(url, soup, base_dir, depth, visited_urls, crawl_depth_limit):\n",
        "    # Download images\n",
        "    for img_tag in soup.find_all(\"img\", src=True):\n",
        "        img_url = urljoin(url, img_tag['src'])\n",
        "        download_resource(img_url, base_dir, 'images', visited_urls, crawl_depth_limit, depth)\n",
        "\n",
        "    # Download JavaScript files\n",
        "    for script_tag in soup.find_all(\"script\", src=True):\n",
        "        script_url = urljoin(url, script_tag['src'])\n",
        "        download_resource(script_url, base_dir, 'js', visited_urls, crawl_depth_limit, depth)\n",
        "\n",
        "# Helper function to download individual resources (like images, js)\n",
        "def download_resource(resource_url, base_dir, resource_type, visited_urls, crawl_depth_limit, depth):\n",
        "    if resource_url in visited_urls or depth > crawl_depth_limit:\n",
        "        return\n",
        "\n",
        "    # Mark this resource as visited\n",
        "    visited_urls.add(resource_url)\n",
        "\n",
        "    try:\n",
        "        response = requests.get(resource_url)\n",
        "        response.raise_for_status()\n",
        "        content = response.content\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"Error downloading resource {resource_url}: {e}\")\n",
        "        return\n",
        "\n",
        "    # Determine the resource directory\n",
        "    resource_dir = os.path.join(base_dir, resource_type)\n",
        "    os.makedirs(resource_dir, exist_ok=True)\n",
        "\n",
        "    # Save the resource locally\n",
        "    resource_name = os.path.basename(urlparse(resource_url).path)\n",
        "    resource_path = os.path.join(resource_dir, resource_name)\n",
        "    with open(resource_path, 'wb') as f:\n",
        "        f.write(content)\n",
        "    print(f\"Downloaded {resource_url} to {resource_path}\")\n",
        "\n",
        "# Function to save the HTML page\n",
        "def save_html(url, page_content, base_dir):\n",
        "    parsed_url = urlparse(url)\n",
        "    file_name = parsed_url.netloc + parsed_url.path.replace('/', '_') + \".html\"\n",
        "    if file_name.endswith(\".html\"):\n",
        "        file_name = file_name.replace(\".html_\", \".html\")\n",
        "    file_path = os.path.join(base_dir, file_name)\n",
        "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
        "    with open(file_path, 'w', encoding='utf-8') as f:\n",
        "        f.write(page_content)\n",
        "    print(f\"Downloaded HTML for {url} to {file_path}\")\n",
        "\n",
        "# Main function to run the downloader\n",
        "def download_website(url, crawl_depth):\n",
        "    base_dir = \"offline_site\"\n",
        "    visited_urls = set()\n",
        "    download_page(url, 0, base_dir, visited_urls, crawl_depth)\n",
        "    print(\"Download completed.\")\n",
        "\n",
        "# Example usage - Change these variables\n",
        "url_to_download = \"https://www.example.com\"  # Replace with the website you want to download\n",
        "crawl_depth = 2  # Replace with your desired crawl depth\n",
        "\n",
        "# Run the download\n",
        "download_website(url_to_download, crawl_depth)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnYV9KxCrfA4",
        "outputId": "fec0a1eb-ae5d-407c-e519-3135c0c1cba8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded HTML for https://www.example.com to offline_site/www.example.com.html\n",
            "Downloaded HTML for https://www.iana.org/domains/example to offline_site/www.iana.org_domains_example.html\n",
            "Downloaded https://www.iana.org/_img/2022/iana-logo-header.svg to offline_site/images/iana-logo-header.svg\n",
            "Downloaded https://www.iana.org/_js/jquery.js to offline_site/js/jquery.js\n",
            "Downloaded https://www.iana.org/_js/iana.js to offline_site/js/iana.js\n",
            "Downloaded HTML for https://www.iana.org/ to offline_site/www.iana.org_.html\n",
            "Downloaded HTML for https://www.iana.org/domains to offline_site/www.iana.org_domains.html\n",
            "Downloaded HTML for https://www.iana.org/protocols to offline_site/www.iana.org_protocols.html\n",
            "Downloaded HTML for https://www.iana.org/numbers to offline_site/www.iana.org_numbers.html\n",
            "Downloaded https://www.iana.org/_img/2013.1/rir-map.svg to offline_site/images/rir-map.svg\n",
            "Downloaded HTML for https://www.iana.org/about to offline_site/www.iana.org_about.html\n",
            "Downloaded HTML for https://www.iana.org/go/rfc2606 to offline_site/www.iana.org_go_rfc2606.html\n",
            "Downloaded HTML for https://www.iana.org/go/rfc6761 to offline_site/www.iana.org_go_rfc6761.html\n",
            "Downloaded HTML for https://www.iana.org/domains/reserved to offline_site/www.iana.org_domains_reserved.html\n",
            "Downloaded HTML for https://www.iana.org/domains/root to offline_site/www.iana.org_domains_root.html\n",
            "Downloaded HTML for https://www.iana.org/domains/int to offline_site/www.iana.org_domains_int.html\n",
            "Downloaded HTML for https://www.iana.org/domains/arpa to offline_site/www.iana.org_domains_arpa.html\n",
            "Downloaded HTML for https://www.iana.org/domains/idn-tables to offline_site/www.iana.org_domains_idn-tables.html\n",
            "Downloaded HTML for https://www.iana.org/abuse to offline_site/www.iana.org_abuse.html\n",
            "Downloaded HTML for https://www.iana.org/time-zones to offline_site/www.iana.org_time-zones.html\n",
            "Downloaded HTML for https://www.iana.org/performance to offline_site/www.iana.org_performance.html\n",
            "Downloaded https://www.iana.org/_img/2022/icon-perf-sla.svg to offline_site/images/icon-perf-sla.svg\n",
            "Downloaded https://www.iana.org/_img/2022/icon-perf-csat.svg to offline_site/images/icon-perf-csat.svg\n",
            "Downloaded https://www.iana.org/_img/2022/icon-perf-sys-ok.svg to offline_site/images/icon-perf-sys-ok.svg\n",
            "Downloaded https://www.iana.org/_img/2022/icon-perf-sec-ok.svg to offline_site/images/icon-perf-sec-ok.svg\n",
            "Downloaded HTML for https://www.iana.org/reports to offline_site/www.iana.org_reports.html\n",
            "Downloaded HTML for https://www.iana.org/reviews to offline_site/www.iana.org_reviews.html\n",
            "Downloaded HTML for https://www.iana.org/about/excellence to offline_site/www.iana.org_about_excellence.html\n",
            "Downloaded https://www.iana.org/about/excellence/efqm-committed-2013.svg to offline_site/images/efqm-committed-2013.svg\n",
            "Downloaded HTML for https://www.iana.org/contact to offline_site/www.iana.org_contact.html\n",
            "Error downloading http://pti.icann.org: HTTPConnectionPool(host='pti.icann.org', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7cebf9cb7110>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "Error downloading http://www.icann.org/: 403 Client Error: Forbidden for url: http://www.icann.org/\n",
            "Downloaded HTML for https://www.icann.org/privacy/policy to offline_site/www.icann.org_privacy_policy.html\n",
            "Downloaded https://www.icann.org/assets/icann_logo-51bd602f4ae463db6a5cd5831c82794cae7ce2f3a61ca47d529c2f4000ccea84.png to offline_site/images/icann_logo-51bd602f4ae463db6a5cd5831c82794cae7ce2f3a61ca47d529c2f4000ccea84.png\n",
            "Downloaded https://www.icann.org/cdn-cgi/scripts/5c5dd728/cloudflare-static/email-decode.min.js to offline_site/js/email-decode.min.js\n",
            "Downloaded https://www.icann.org/assets/application-8ed45bf72fd6cd126948eea999721de19b3fcd2cc80521f694b544d621b3107f.js to offline_site/js/application-8ed45bf72fd6cd126948eea999721de19b3fcd2cc80521f694b544d621b3107f.js\n",
            "Downloaded https://www.icann.org/glossary_terms.js to offline_site/js/glossary_terms.js\n",
            "Downloaded https://www.icann.org/assets/resource_pages-e9c0276a0a22bcc7866e5ad132448d3d25d51eb3166ac7e56f2debba96064762.js to offline_site/js/resource_pages-e9c0276a0a22bcc7866e5ad132448d3d25d51eb3166ac7e56f2debba96064762.js\n",
            "Downloaded HTML for https://www.icann.org/privacy/tos to offline_site/www.icann.org_privacy_tos.html\n",
            "Download completed.\n"
          ]
        }
      ]
    }
  ]
}